Kafka Deep Dive :-

Usage : Used mainly for high throughput event streaming and message queing.

Components

1. Producers (Publish messages using Producer Api)
2. Consumers (Consume messages using Consumer Api)
3. Kafka Cluster (Holds the brain of the system ,eg - All consumers commit their offsetr values to the cluster for use in case they go down)
4. Message Brokers (Receives messages and routes them to the designated partition)
5. Partition (Used for separating traffic by use case of scalability. It is a queue itself, can be thought of as a separate log file on disk)
6. Topics (Logical division of partitions. Its a way of organising the data for the application itself)
7. Partition Key (Present in every message. Used to decide which partition , this message is destined for.)
8. Consumer Groups (Used primarily to ensure that a message from a topic is consumed only once. Generally every consumer group has a designated topic. Every consumer in a group has a designated partition range from which to consume.)

Deep Dives :- 

1. Scalability
    - Create multiple brokers (1 broker typically can be assumed to handle 10k messages and total 1 TB data offcourse with suitable hardware)
    - Aim to keep message size < 1 MB
    - Choose a good partitioning key (so that messages are evenly distributed across partitions)
    - How to deal with a hot partition ? - Add a suffix to the key,eg If the original key was addidas-key, make it as addidas-key:n where n is (1,10). So this way , the traffic gets distributed within 10 ndifferent partitions. 
                                           Also we can use Backpressure, that is slow down the Producer itself.
2. Duarability and Fault Tolerance
    - Each partition has replicas (called followers). The original one is called the leader and it has followers who sync up the messages from the leader and stay prepared to take over incase the leader goes down.
    - There are 2 main configs
        replicas - no.of followers 
        ack - the no.of followers that need to acknowledge a message before moving on the next one
        Higher the ack - more is the durability but slower are the operations and vice versa. 
3. Error and Retries
     - there is a in-built retry mechanism in the Kafka Producer api for retrying with time intervals. Use idempotent mode to prevent duplicate messages while retrying.
     - On the Consumer side ,there is no inbuilt mechanism, but for the sake of failed jobs , we can push them to a retry partition from where they will be re consumed. After a certain number of retries , if they still fail we can push them to a final partition which is generally known as the Dead Letter Queue.
4. Data Retention Policy
     - there are 2 parameters 
        retention.ms - time period for which a message is retained (default is 7 days)
        retention.size - size limit till which a message is retained (default is 1 GB)
5. Performance Optimization
    - Batch messages in the producer (while batching use 2 parameters - maxtime[time period for which messages are batched],maxsize[size limit of a batch])
    - Compress messages in the Producer (inbuilt mechanism)


